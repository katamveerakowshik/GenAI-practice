{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc036b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7433523b",
   "metadata": {},
   "source": [
    "# Sequantial Runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f1a2324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the programmer quit his job?\n",
      "\n",
      "Because he didn't get arrays of opportunities! (get it?)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "template = PromptTemplate(\n",
    "    template = \"Give me a joke about {topic}\",\n",
    "    input_variables = [\"topic\"])\n",
    "parser = StrOutputParser()\n",
    "\n",
    "runnable = RunnableSequence(template, llm, parser)\n",
    "print(runnable.invoke({\"topic\": \"programming\"}))  # \"Why did the programmer quit his job?\\n\\nBecause he didn't get arrays! (get it?)\"runnable.invoke({\"topic\": \"programming\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cf22ec",
   "metadata": {},
   "source": [
    "# Runnable Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e219b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tweet': '\"AI is not just a tool, it\\'s a reflection of our future. As we continue to innovate and improve, let\\'s remember that with great power comes great responsibility. How do you think AI will shape our world in the next 5 years? #AI #FutureOfTech\"', 'linkedin_post': 'Here\\'s a potential LinkedIn post about AI:\\n\\n**\"The Future of Work: Embracing the Power of Artificial Intelligence**\\n\\nAs we continue to navigate the ever-changing landscape of work, one thing is clear: Artificial Intelligence (AI) is here to stay. From automation to personalization, AI is transforming industries and revolutionizing the way we work.\\n\\nBut what does this mean for you? How can you harness the power of AI to enhance your skills, boost productivity, and drive innovation?\\n\\nHere are a few ways to get started:\\n\\n **Upskill and reskill**: Invest in training and development programs that focus on emerging technologies like AI, data science, and machine learning.\\n\\n **Leverage AI tools**: Explore AI-powered tools and platforms that can help you automate repetitive tasks, streamline processes, and gain insights from large datasets.\\n\\n **Collaborate with experts**: Build relationships with professionals who are already working with AI in their industries, and learn from their experiences.\\n\\n **Stay curious**: Continuously seek out new information and updates on the latest advancements in AI, and be open to learning and adapting.\\n\\nThe future of work is rapidly changing, but one thing remains constant: the need for innovation, creativity, and adaptability. By embracing AI and staying ahead of the curve, you can position yourself for success in an increasingly automated world.\\n\\nLet\\'s connect! Share your thoughts on how you\\'re leveraging AI in your work or personal life, and let\\'s continue the conversation!\\n\\n#AI #ArtificialIntelligence #FutureOfWork #SkillsDevelopment #ProductivityHacks\"\\n\\nFeel free to customize it as per your preference and style.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template = \"Give me a tweet on {topic}\",\n",
    "    input_variables = [\"topic\"])\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Give me a linkedin post on {topic}\",\n",
    "    input_variables = [\"topic\"])\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "#Note that Runnable Parallel takes a dictionary where the keys are the names of the runnables and the values are the runnables themselves. When we invoke the RunnableParallel, it will return a dictionary where the keys are the same as the input dictionary and the values are the outputs of the respective runnables.\n",
    "runnable_parallel = RunnableParallel({\n",
    "    \"tweet\": RunnableSequence(prompt1, llm, parser),\n",
    "    \"linkedin_post\": RunnableSequence(prompt2, llm, parser)\n",
    "})\n",
    "\n",
    "print(runnable_parallel.invoke({\"topic\": \"AI\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5438f",
   "metadata": {},
   "source": [
    "# Runnable PassThrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dec89e3",
   "metadata": {},
   "source": [
    "### Runnable Passthrough just takes the input and prints the same output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e73f0d",
   "metadata": {},
   "source": [
    "Walkthrought: prompt1 --> model --> generate joke then 2 parallel chains, one for printing joke (Runnable Passthrough) other for explaining the joke (prompt2 --> model --> explain joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb262de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'Why did the AI program go to therapy?\\n\\nBecause it was struggling with its \"bytes\" of emotions! (get it?)', 'explanation': 'A clever play on words!\\n\\nThe joke relies on a pun, which is a type of wordplay that exploits multiple meanings or sounds of words.\\n\\nIn this case, the punchline \"bytes of emotions\" has a double meaning:\\n\\n1. In computing, a \"byte\" refers to a unit of digital information.\\n2. Emotions are feelings or emotional states.\\n\\nSo, when the joke says the AI program is struggling with its \"bytes\" of emotions, it\\'s playing on this dual meaning. It\\'s as if the AI is having trouble managing its own digital code (bytes) and also dealing with emotional turmoil. The humor comes from the unexpected twist on the usual meaning of \"bytes\"!\\n\\nThe use of parentheses \"(get it?)\" also implies that the speaker expects the listener to catch the pun and appreciate the clever wordplay.\\n\\nI hope this explanation helped clarify the joke!'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template = \"Give me a joke on {topic}\",\n",
    "    input_variables = [\"topic\"])\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Explain me this joke: {joke}\",\n",
    "    input_variables = [\"joke\"])\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "joke_generator = RunnableSequence(prompt1, llm, parser)\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"joke\": RunnablePassthrough(),\n",
    "    \"explanation\": RunnableSequence(prompt2, llm, parser)\n",
    "})\n",
    "\n",
    "runnable = RunnableSequence(joke_generator, parallel_chain)\n",
    "print(runnable.invoke({\"topic\": \"AI\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11264b0b",
   "metadata": {},
   "source": [
    "# Runnable Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9148b67",
   "metadata": {},
   "source": [
    "It is used to make functions into a runnable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7994995",
   "metadata": {},
   "source": [
    "Walkthrough: prompt--> model --> joke. Then we have a parallel runnable, first one just prints the joke (RunnablePassthrough) and the second one is to count no.of words in the joke (RunnableLambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c452710f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joke': 'Why did the AI program go to therapy?\\n\\nBecause it was struggling to process its emotions.', 'no_of_words': 16}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def no_of_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Give me a joke on {topic}\",\n",
    "    input_variables = [\"topic\"])\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "parser = StrOutputParser()\n",
    "\n",
    "joke_generator = RunnableSequence(prompt, llm, parser)  \n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"joke\": RunnablePassthrough(),\n",
    "    \"no_of_words\": RunnableLambda(no_of_words)})\n",
    "\n",
    "runnable = RunnableSequence(joke_generator, parallel_chain)\n",
    "result = runnable.invoke({\"topic\": \"AI\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b898e3",
   "metadata": {},
   "source": [
    "# Runnable Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b62c82",
   "metadata": {},
   "source": [
    "It is basically used for conditional logics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ec722",
   "metadata": {},
   "source": [
    "Walkthrough: Prompt --> llm --> response. Then if len(response) is greater than 300, we summarise is or else we print it as it is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fb9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This report provides a thorough and well-structured overview of Artificial Intelligence (AI), covering its history, types, applications, machine learning, deep learning, ethics, challenges, and future prospects.\n",
      "\n",
      "The report begins by introducing AI as the development of computer systems that can perform tasks typically requiring human intelligence, such as learning, problem-solving, and decision-making. It then delves into the history of AI, tracing back to ancient Greece and highlighting the contributions of pioneers like John McCarthy who coined the term \"Artificial Intelligence\" in 1956.\n",
      "\n",
      "The report categorizes AI into three types: Narrow or Weak AI, General or Strong AI, and Superintelligence. Narrow AI is designed to perform specific tasks, while general AI aims to create machines that can think and learn like humans. Superintelligence refers to an intelligent machine that surpasses human intelligence in all domains.\n",
      "\n",
      "AI has numerous applications across various industries, including virtual assistants, image recognition, natural language processing, predictive maintenance, healthcare, and more. Machine learning is a key subset of AI that involves training algorithms on data to enable them to make predictions or decisions without being explicitly programmed.\n",
      "\n",
      "The report also discusses deep learning, which uses neural networks with multiple layers to analyze complex data sets. It highlights the importance of explainability and transparency in AI systems, as well as the need to address ethical concerns such as bias, job displacement, security, and privacy.\n",
      "\n",
      "The future of AI is promising, with significant advancements expected in areas like explainability, edge AI, and human-AI collaboration. The report concludes by emphasizing the need for education, diversity, and inclusion in AI development and deployment.\n",
      "\n",
      "In terms of recommendations, the report suggests investing in education and training programs that focus on AI-related skills and knowledge, encouraging diversity and inclusion in AI development teams, and developing explainable AI systems.\n",
      "\n",
      "Overall, this comprehensive report provides a solid foundation for understanding Artificial Intelligence and its vast potential to transform various industries and aspects of society.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Give me detailed report on {topic}\",\n",
    "    input_variables = [\"topic\"])\n",
    "\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Give me a short summary of {text}\",\n",
    "    input_variables = [\"text\"])\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:latest\")\n",
    "parser = StrOutputParser()  \n",
    "\n",
    "report_generator = RunnableSequence(prompt, llm, parser)\n",
    "\n",
    "branch = RunnableBranch(\n",
    "    ((lambda x: len(x.split()) > 300), RunnableSequence(prompt2, llm, parser)),\n",
    "    RunnablePassthrough()\n",
    ")\n",
    "\n",
    "runnable = RunnableSequence(report_generator, branch)\n",
    "result = runnable.invoke({\"topic\": \"AI\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
